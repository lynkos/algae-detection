{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.cuda import empty_cache as empty_cuda_cache, is_available as is_cuda_available\n",
        "from torch.mps import empty_cache as empty_mps_cache\n",
        "from torch.backends.mps import is_available as is_mps_available\n",
        "from gc import collect\n",
        "\n",
        "def reset_model(model, has_model: bool = True):\n",
        "    if is_cuda_available(): empty_cuda_cache()\n",
        "    elif is_mps_available(): empty_mps_cache()\n",
        "    \n",
        "    if has_model: del model\n",
        "\n",
        "    collect()\n",
        "    globals().clear()\n",
        "\n",
        "%reset -f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "1b9c0d34-4c39-4175-c58f-4bd892d9e159"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.8 torch-2.2.2 CPU (Apple M3 Max)\n",
            "Setup complete âœ… (16 CPUs, 64.0 GB RAM, 658.7/1858.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from ultralytics import checks\n",
        "\n",
        "clear_output()\n",
        "checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from subprocess import run, PIPE\n",
        "\n",
        "def run_command(command: str, **kwargs):\n",
        "    \"\"\"\n",
        "    Run command with optional arguments. Examples:\n",
        "    \n",
        "    run_command(\"yolo\", task=\"detect\", mode=\"predict\")\n",
        "    run_command(\"yolo task=detect mode=predict\")\n",
        "\n",
        "    Args:\n",
        "        command (str): Command to be run\n",
        "    \"\"\"\n",
        "    if not kwargs:\n",
        "        cmd = command.split(\" \")    \n",
        "\n",
        "    else:\n",
        "        cmd = [ command ]\n",
        "        for key, value in kwargs.items():\n",
        "            cmd.append(f\"{key}={value}\")\n",
        "\n",
        "    result = run(cmd, stdout = PIPE)\n",
        "    output = result.stdout.decode()\n",
        "    print(output)\n",
        "    #return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: mps (mps)\n"
          ]
        }
      ],
      "source": [
        "from torch import device\n",
        "from torch.cuda import is_available as is_cuda_available\n",
        "from torch.backends.mps import is_available as is_mps_available\n",
        "\n",
        "BACKEND = \"mps\" if is_mps_available() else \"cuda\" if is_cuda_available() else \"cpu\"\n",
        "DEVICE = device(BACKEND)\n",
        "print(f\"Device: {DEVICE} ({BACKEND})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/kiran/Documents/workspace/Projects/algae-detection\n"
          ]
        }
      ],
      "source": [
        "from os import curdir\n",
        "from os.path import abspath\n",
        "\n",
        "HOME = abspath(curdir)\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "def output_img(path, height=600):\n",
        "    display(Image(filename=path, width=height, height=height))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JHICVjZbVKn"
      },
      "source": [
        "## Get customÂ dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"OZYVRHRpfy8DaxBPca6s\")\n",
        "project = rf.workspace(\"capstone2algae\").project(\"algae-detection-1opyx\")\n",
        "VERSION = 9\n",
        "version = project.version(VERSION)\n",
        "#dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if DEVICE == \"mps\":\n",
        "    from os import cpu_count\n",
        "    from json import loads\n",
        "\n",
        "    out = loads(run_command(\"system_profiler -json -detailLevel mini SPDisplaysDataType\")) # type: ignore\n",
        "    gpus = int(out['SPDisplaysDataType'][0]['sppci_cores'])\n",
        "    cpus = cpu_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "yolov8_weights= f\"{HOME}/weights/yolov8n.pt\"\n",
        "confidence = 0.25\n",
        "epochs = 3\n",
        "img_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.mps import empty_cache\n",
        "empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "_J35i8Ofhjxa",
        "outputId": "5e1df394-1515-4e45-90ba-4d668b8b6e6a"
      },
      "outputs": [],
      "source": [
        "output_img(f'{HOME}/runs/detect/train2/confusion_matrix.png', 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "A-urTWUkhRmn",
        "outputId": "355772eb-6d9f-49fd-d46c-674d83d6fd6c"
      },
      "outputs": [],
      "source": [
        "output_img(f'{HOME}/runs/detect/train2/results.png', 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "HI4nADCCj3F5",
        "outputId": "743bd2b5-5d46-44d2-e8a7-ce22c2024306"
      },
      "outputs": [],
      "source": [
        "output_img(f'{HOME}/runs/detect/train2/val_batch0_pred.jpg', 600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyuwrNlXc1P",
        "outputId": "0a1b7ba8-54a2-40c7-8f6b-514153656c1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.8 torch-2.2.2 MPS (Apple M3 Max)\n",
            "Model summary (fused): 268 layers, 68127420 parameters, 0 gradients, 257.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/kiran/Documents/workspace/Projects/algae-detection/algae_ds/valid/labels.cache... 82 images, 15 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.23it/s]\n",
            "                   all         82         79          0          0          0          0\n",
            "Speed: 0.3ms preprocess, 27.4ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ds_location = \"\"\n",
        "run_command(f\"yolo task=detect mode=val plots=True imgsz={img_size} device={DEVICE} model={HOME}/runs/detect/train2/weights/best.pt data={ds_location}/data.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "**NOTE:** Let's take a look at few results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "jbVjEtPAkz3j",
        "outputId": "e44337d8-9da8-4634-cbe7-23bc5759ddbe"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "for image_path in glob(f'{HOME}/runs/detect/predict3/*.jpg'):\n",
        "      output_img(image_path)\n",
        "      print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0tsVilOCPyq"
      },
      "source": [
        "## Deploy model on Roboflow\n",
        "\n",
        "Once you have finished training your YOLOv8 model, youâ€™ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
        "\n",
        "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n",
        "\n",
        "To upload model weights, add the following code to the â€œInference with Custom Modelâ€ section in the aforementioned notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EhBAJ2gCPZh",
        "outputId": "259decf5-1c4e-4011-a208-a2498acc30ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the status of your deployment at: https://app.roboflow.com/capstone2algae/algae-detection-1opyx/9\n",
            "Share your model with the world at: https://universe.roboflow.com/capstone2algae/algae-detection-1opyx/model/9\n"
          ]
        }
      ],
      "source": [
        "project.version(VERSION).deploy(model_type=\"yolov8\", model_path=f\"{HOME}\", filename=\"weights/best_sahi_v1.pt\")\n",
        "\n",
        "#version.deploy(\"yolov8\", \"weights\", \"best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "I4bpUIibcV1l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running inference on 20230609095008_jpg.rf.e5fcc5b326446114316e5422b3f3a9d4.jpg\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'predictions': [], 'image': {'width': '256', 'height': '256'}}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Run inference on your model on a persistant, auto-scaling, cloud API\n",
        "\n",
        "#load model\n",
        "model = project.version(VERSION).model\n",
        "\n",
        "#choose random test set image\n",
        "from os import listdir\n",
        "from random import choice\n",
        "\n",
        "#model = YOLO(model = f\"/Users/kiran/Documents/workspace/Projects/algae-detection/weights/best.pt\", task = \"predict\")\n",
        "\n",
        "ds_location = \"algae_ds\"\n",
        "#run_command(f\"yolo task=detect mode=predict imgsz={img_size} model={HOME}/runs/detect/train2/weights/best.pt source={ds_location}/test/images device={DEVICE} save=True\")\n",
        "\n",
        "test_set_loc = f\"{ds_location}/test/images/\"\n",
        "random_test_image = choice(listdir(test_set_loc))\n",
        "print(f\"running inference on {random_test_image}\")\n",
        "\n",
        "model.predict(f\"{test_set_loc}{random_test_image}\").json()\n",
        "#reset_model(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

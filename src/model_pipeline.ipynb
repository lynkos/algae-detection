{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.cuda import empty_cache as empty_cuda_cache, is_available as is_cuda_available\n",
        "from torch.mps import empty_cache as empty_mps_cache\n",
        "from torch.backends.mps import is_available as is_mps_available\n",
        "from gc import collect\n",
        "\n",
        "def reset_model(model, has_model: bool = True):\n",
        "    if is_cuda_available(): empty_cuda_cache()\n",
        "    elif is_mps_available(): empty_mps_cache()\n",
        "    \n",
        "    if has_model: del model\n",
        "\n",
        "    collect()\n",
        "    globals().clear()\n",
        "\n",
        "%reset -f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "1b9c0d34-4c39-4175-c58f-4bd892d9e159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.47 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M3 Max)\n",
            "Setup complete ‚úÖ (16 CPUs, 64.0 GB RAM, 664.9/1858.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from ultralytics import checks\n",
        "\n",
        "clear_output()\n",
        "checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: mps (mps)\n"
          ]
        }
      ],
      "source": [
        "from torch import device\n",
        "from torch.cuda import is_available as is_cuda_available\n",
        "from torch.backends.mps import is_available as is_mps_available\n",
        "\n",
        "BACKEND = \"mps\" if is_mps_available() else \"cuda\" if is_cuda_available() else \"cpu\"\n",
        "DEVICE = device(BACKEND)\n",
        "print(f\"Device: {DEVICE} ({BACKEND})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/kiran/Documents/workspace/Projects/algae-detection\n"
          ]
        }
      ],
      "source": [
        "from os import getcwd\n",
        "from os.path import dirname\n",
        " \n",
        "HOME = dirname(getcwd())\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "def output_img(path, height=600):\n",
        "    display(Image(filename=path, width=height, height=height))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JHICVjZbVKn"
      },
      "source": [
        "## Get custom¬†dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"OZYVRHRpfy8DaxBPca6s\")\n",
        "project = rf.workspace(\"capstone2algae\").project(\"algae-detection-1opyx\")\n",
        "VERSION = 9\n",
        "version = project.version(VERSION)\n",
        "#dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/kiran/Documents/workspace/Projects/algae-detection\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "using dhist requires you to install the `pickleshare` library.\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "yolov8_weights= f\"{HOME}/weights/yolov8x.pt\"\n",
        "confidence = 0.25\n",
        "epochs = 3\n",
        "img_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyuwrNlXc1P",
        "outputId": "0a1b7ba8-54a2-40c7-8f6b-514153656c1e"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "ds_location = f\"{HOME}/dataset/algae_ds\"\n",
        "model = YOLO(model=yolov8_weights)\n",
        "model.train(data=f\"{ds_location}/data.yaml\", plots=True, epochs=epochs, imgsz=img_size, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "_J35i8Ofhjxa",
        "outputId": "5e1df394-1515-4e45-90ba-4d668b8b6e6a"
      },
      "outputs": [],
      "source": [
        "output_img(f'{HOME}/runs/detect/train/confusion_matrix.png', 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "A-urTWUkhRmn",
        "outputId": "355772eb-6d9f-49fd-d46c-674d83d6fd6c"
      },
      "outputs": [],
      "source": [
        "output_img(f'{HOME}/runs/detect/train/results.png', 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "HI4nADCCj3F5",
        "outputId": "743bd2b5-5d46-44d2-e8a7-ce22c2024306"
      },
      "outputs": [],
      "source": [
        "output_img(f'{HOME}/runs/detect/train/val_batch0_pred.jpg', 600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4bpUIibcV1l"
      },
      "outputs": [],
      "source": [
        "#load model\n",
        "model = project.version(VERSION).model\n",
        "\n",
        "#choose random test set image\n",
        "from os import listdir\n",
        "from random import choice\n",
        "\n",
        "test_set_loc = f\"{ds_location}/test/images/\"\n",
        "random_test_image = choice(listdir(test_set_loc))\n",
        "print(f\"running inference on {random_test_image}\")\n",
        "model = YOLO(model=f\"{HOME}/weights/yolov8x.pt\")\n",
        "\n",
        "if model: model.predict(f\"{test_set_loc}{random_test_image}\", imgsz=img_size, conf=confidence, save=True, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "for image_path in glob(f'{HOME}/runs/detect/predict/*.jpg'):\n",
        "      output_img(image_path)\n",
        "      print(\"\\n\")\n",
        "#reset_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0tsVilOCPyq"
      },
      "source": [
        "## Deploy model on Roboflow\n",
        "\n",
        "Once you have finished training your YOLOv8 model, you‚Äôll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
        "\n",
        "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n",
        "\n",
        "To upload model weights, add the following code to the ‚ÄúInference with Custom Model‚Äù section in the aforementioned notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EhBAJ2gCPZh",
        "outputId": "259decf5-1c4e-4011-a208-a2498acc30ca"
      },
      "outputs": [],
      "source": [
        "#project.version(VERSION).deploy(model_type=\"yolov8\", model_path=f\"{HOME}/runs/detect/train\")\n",
        "\n",
        "version.deploy(\"yolov8\", \"weights\", \"best.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
